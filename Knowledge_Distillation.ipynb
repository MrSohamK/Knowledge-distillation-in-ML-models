{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0ilryOw7-1EM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "v33Gz4OW_160"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Distillation model along with its loss, this will train the student model from the teacher model\n",
        "class Distiller(nn.Module):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        self.optimizer = optimizer\n",
        "        self.metrics = metrics\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def compute_loss(self, x, y, y_pred, sample_weight=None, allow_empty=False):\n",
        "        teacher_pred = self.teacher(x)\n",
        "        student_loss = self.student_loss_fn(y_pred, y)\n",
        "\n",
        "        teacher_softened = F.softmax(teacher_pred / self.temperature, dim=1)\n",
        "        student_softened = F.softmax(y_pred / self.temperature, dim=1)\n",
        "\n",
        "        distillation_loss = self.distillation_loss_fn(\n",
        "            student_softened,\n",
        "            teacher_softened\n",
        "        ) * (self.temperature ** 2)\n",
        "\n",
        "        loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.student(x)"
      ],
      "metadata": {
        "id": "RzxSOeHL_W5z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RBMPRFhIABS4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the student class\n",
        "class Student(nn.Module):\n",
        "    ''' Models a simple Convolutional Neural Network'''\n",
        "\n",
        "# Instantiate the network layers\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Student, self).__init__()\n",
        "\t# 3 input image channel, 8 output channels,\n",
        "  # The image is 32x32 so after applying 5x5 kernel we get 28x28 image\n",
        "\t# 5x5 square convolution kernel, represented by the last argument 5\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 8, 5)\n",
        "\n",
        "\t# Max pooling over a (2, 2) window\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(8, 18, 5)\n",
        "\n",
        "        # after this we apply 2X2 pooling which basically halves the dimension of image along height and width, here we have just defined it, we will actually apply in the forward method\n",
        "        # That is why image dimemsion becomes 5*5 from 10*10\n",
        "        self.fc1 = nn.Linear(18 * 5 * 5, 120) # 5x5 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 18 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zzBLBZbfAVb-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "student = Student()\n",
        "\n",
        "# Clone student for later comparison\n",
        "import copy\n",
        "student_scratch = copy.deepcopy(student)"
      ],
      "metadata": {
        "id": "u0zD8ZgJB8aw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# python image library of range [0, 1]\n",
        "# transform them to tensors of normalized range[-1, 1]\n",
        "\n",
        "transform = transforms.Compose( # composing several transforms together\n",
        "    [transforms.ToTensor(), # to tensor object\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # mean = 0.5, std = 0.5\n",
        "\n",
        "# set batch_size\n",
        "batch_size = 4\n",
        "\n",
        "# set number of workers\n",
        "num_workers = 2\n",
        "\n",
        "# load train data\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=num_workers)\n",
        "\n",
        "# load test data\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# put 10 classes into a set\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COkTcjEMEN1Z",
        "outputId": "aab9afca-8e8f-4873-bee0-b7a0e3802729"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 13022375.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "EChn-wEsEkO8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(student.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "2aTYYHKYEuqJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "resnet18 = models.resnet18(pretrained = True)\n",
        "squeezenet = models.squeezenet1_0(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zABPJW3IH0H7",
        "outputId": "1df5a804-97a1-4e76-f077-9ebd3a718178"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 191MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_0_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-b66bff10.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_0-b66bff10.pth\n",
            "100%|██████████| 4.78M/4.78M [00:00<00:00, 168MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "0roNzS5lJ57o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43f90d9-6a00-4710-ff52-2d2ec70963b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.4.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Downloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/869.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.7 torchmetrics-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher = models.resnet18(pretrained=True)\n",
        "teacher.fc = nn.Sequential(\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 10)\n",
        ")  # Modify the output layer to match the number of classes in your dataset\n",
        "\n",
        "# Freeze the parameters of the teacher model\n",
        "for param in teacher.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "Xj1tdi6XOeBT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "\n",
        "# Initialize and compile distiller\n",
        "\n",
        "distiller = Distiller(student=student, teacher = teacher)\n",
        "\n",
        "optimizer = optim.Adam(distiller.parameters())\n",
        "metrics = {'accuracy': torchmetrics.Accuracy(task='MULTICLASS', num_classes = 10)}\n",
        "\n",
        "def student_loss_fn(outputs, labels):\n",
        "    return F.cross_entropy(outputs, labels)\n",
        "\n",
        "def distillation_loss_fn(student_logits, teacher_probs):\n",
        "    return torch.nn.KLDivLoss()(F.log_softmax(student_logits / distiller.temperature, dim=1), teacher_probs)"
      ],
      "metadata": {
        "id": "pcXkr52cIHxt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distiller.compile(\n",
        "    optimizer=optimizer,\n",
        "    metrics=metrics,\n",
        "    student_loss_fn=student_loss_fn,\n",
        "    distillation_loss_fn=distillation_loss_fn,\n",
        "    alpha=0.1,\n",
        "    temperature=10\n",
        ")"
      ],
      "metadata": {
        "id": "Hd_vXSwYJzPH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train distiller\n",
        "def train_distiller(model, train_loader, criterion, optimizer, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            student_logits = model(inputs)\n",
        "            teacher_probs = teacher(inputs)\n",
        "            loss = criterion(inputs, labels, student_logits, teacher_probs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "id": "U1YHqHQnMQak"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 4\n",
        "train_distiller(distiller, trainloader, distiller.compute_loss, optimizer, epochs)\n"
      ],
      "metadata": {
        "id": "kSNzc91lMUHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aeb1ac2-5281-434b-d297-c31996748b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/4], Loss: 0.1785\n",
            "Epoch [2/4], Loss: 0.1517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate distiller on test dataset\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "F-8jVeTjYd0g"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(distiller, testloader)"
      ],
      "metadata": {
        "id": "gsav-WWjbFWP",
        "outputId": "3c141f29-9ec1-411c-d696-6343883ba1b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = teacher(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "id": "BjgPFoTa0akH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757f5eb8-4c98-4def-bec2-ee65730ec884"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 9 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training student model without the teacher model\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "start.record()\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = student_scratch(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "# whatever you are timing goes here\n",
        "end.record()\n",
        "\n",
        "# Waits for everything to finish running\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "print('Finished Training')\n",
        "print(start.elapsed_time(end))  # milliseconds"
      ],
      "metadata": {
        "id": "jwTZs1_BExGW",
        "outputId": "b5a3bdd2-f46d-4750-de1d-ead635c71b39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.304\n",
            "[1,  4000] loss: 2.303\n",
            "[1,  6000] loss: 2.304\n",
            "[1,  8000] loss: 2.303\n",
            "[1, 10000] loss: 2.304\n",
            "[1, 12000] loss: 2.305\n",
            "[2,  2000] loss: 2.303\n",
            "[2,  4000] loss: 2.304\n",
            "[2,  6000] loss: 2.304\n",
            "[2,  8000] loss: 2.304\n",
            "[2, 10000] loss: 2.304\n",
            "[2, 12000] loss: 2.304\n",
            "Finished Training\n",
            "130384.203125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance of student model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = student(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "id": "WBCh13XcGuy2",
        "outputId": "b4b360e5-17ca-49ec-b49a-46f9ddf5b957",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 10 %\n"
          ]
        }
      ]
    }
  ]
}